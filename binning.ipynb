{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt # standard Python plotting library\n",
    "import numpy as np  # fundamental package for scientific computing, handles arrays and math\n",
    "import scipy.signal\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "from pathlib import Path\n",
    "import tdt # import the tdt library\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.signal import find_peaks, peak_prominences, peak_widths\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isosbestic = '_415A'\n",
    "dopa='_465A'\n",
    "CHANNEL = 1\n",
    "TRANGE       = [-5, 10]\n",
    "BASELINE_PER = [-5, 2]\n",
    "event_type = 'RNP_'\n",
    "het_path = r\"N:\\2024April_May_Tanks_GRBDA_RI\\Day4FR1_04272024\\HET/*\" # path to het folder remember /*\n",
    "wt_path = r\"N:\\2024April_May_Tanks_GRBDA_RI\\Day4FR1_04272024\\WTY/*\"\n",
    "\n",
    "\n",
    "def T50_measurement(peaks, widths):\n",
    "    for i in range(len(peaks[0])):\n",
    "        t50 = (peaks[0][i]-widths[2][i])/(2*101.8) # math for correct time units\n",
    "    return t50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from t=0s to t=1800.69s\n"
     ]
    }
   ],
   "source": [
    "blockpath = r\"n:\\2024April_May_Tanks_GRBDA_RI\\Day5_RI30_04282024\\HET\\RI1_EN114_010124-240428-145118\"\n",
    "data = tdt.read_block(blockpath, evtype=['epocs','streams'], channel=CHANNEL)\n",
    "data = tdt.epoc_filter(data, event_type, t=TRANGE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 504.51513344,  525.37065472,  654.95793664,  705.8792448 ,\n",
       "        789.33557248,  990.32236032, 1091.25287936, 1219.44276992,\n",
       "       1377.95567616, 1424.6928384 , 1727.172608  ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.epocs.RNP_.onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [504.51513344, 525.37065472],\n",
       " [654.95793664, 705.8792448],\n",
       " [789.33557248],\n",
       " [990.32236032],\n",
       " [1091.25287936, 1219.44276992],\n",
       " [1377.95567616, 1424.6928384],\n",
       " [],\n",
       " 1727.172608]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = (data.info.duration.seconds) + (data.info.duration.microseconds)*1e-6\n",
    "nbins = 10\n",
    "interval = total_time/nbins\n",
    "binned_epocs = []\n",
    "onsets = data.epocs.RNP_.onset\n",
    "\n",
    "x = interval\n",
    "temp_array = []\n",
    "for i in range(len(onsets)):\n",
    "    while True:\n",
    "        if onsets[i] < x:\n",
    "            temp_array.append(onsets[i])\n",
    "            break\n",
    "        elif onsets[i]>x:\n",
    "            x += interval\n",
    "            binned_epocs.append(temp_array)\n",
    "            temp_array = []\n",
    "            continue\n",
    "        \n",
    "\n",
    "a = (onsets[-1])\n",
    "binned_epocs.append(a)\n",
    "binned_epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 504.51513344,  525.37065472,  654.95793664,  705.8792448 ,\n",
       "        789.33557248,  990.32236032, 1091.25287936, 1219.44276992,\n",
       "       1377.95567616, 1424.6928384 , 1727.172608  ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zall = []\n",
    "for path in glob.glob(het_path):\n",
    "    blockpath = path\n",
    "    data = tdt.read_block(blockpath, evtype=['epocs','streams'], channel=CHANNEL)\n",
    "    data = tdt.epoc_filter(data, event_type, t=TRANGE)  #filters the chosen epocs (RNP_) and time set around those epocs\n",
    "    # More examples of list comprehensions\n",
    "    min1 = np.min([np.size(x) for x in data['streams'][dopa].filtered])\n",
    "    min2 = np.min([np.size(x) for x in data['streams'][isosbestic].filtered])\n",
    "    data['streams'][dopa].filtered = [x[1:min1] for x in data['streams'][dopa].filtered]\n",
    "    data['streams'][isosbestic].filtered = [x[1:min2] for x in data['streams'][isosbestic].filtered]\n",
    "\n",
    "    # Downsample and average 10x via a moving window mean\n",
    "    N = 10 # Average every 10 samples into 1 value\n",
    "    F415 = []\n",
    "    F465 = []\n",
    "    for lst in data['streams'][isosbestic].filtered: \n",
    "        small_lst = []\n",
    "        for i in range(0, min2, N):\n",
    "            small_lst.append(np.mean(lst[i:i+N-1])) # This is the moving window mean\n",
    "        F415.append(small_lst)\n",
    "\n",
    "    for lst in data['streams'][dopa].filtered: \n",
    "        small_lst = []\n",
    "        for i in range(0, min1, N):\n",
    "            small_lst.append(np.mean(lst[i:i+N-1]))\n",
    "        F465.append(small_lst)\n",
    "\n",
    "    #Create a mean signal, standard error of signal, and DC offset\n",
    "    meanF415 = np.mean(F415, axis=0)\n",
    "    stdF415 = np.std(F415, axis=0)/np.sqrt(len(data['streams'][isosbestic].filtered))\n",
    "    dcF415 = np.mean(meanF415)\n",
    "    meanF465 = np.mean(F465, axis=0)\n",
    "    stdF465 = np.std(F465, axis=0)/np.sqrt(len(data['streams'][dopa].filtered))\n",
    "    dcF465 = np.mean(meanF465)\n",
    "    Y_fit_all = []\n",
    "    Y_dF_all = []\n",
    "    for x, y in zip(F415, F465):\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        bls = np.polyfit(x, y, 1)\n",
    "        fit_line = np.multiply(bls[0], x) + bls[1]\n",
    "        Y_fit_all.append(fit_line)\n",
    "        Y_dF_all.append(y-fit_line)\n",
    "    ts1 = TRANGE[0] + np.linspace(1, len(meanF465), len(meanF465))/data['streams'][dopa].fs*N\n",
    "    ts2 = TRANGE[0] + np.linspace(1, len(meanF415), len(meanF415))/data['streams'][isosbestic].fs*N\n",
    "    # Getting the z-score and standard error\n",
    "    zall = []\n",
    "    for dF in Y_dF_all: \n",
    "        ind = np.where((np.array(ts2)<BASELINE_PER[1]) & (np.array(ts2)>BASELINE_PER[0]))\n",
    "        zb = np.mean(dF[ind])\n",
    "        zsd = np.std(dF[ind])\n",
    "        zall.append((dF - zb)/zsd)\n",
    "    ts1 = TRANGE[0] + np.linspace(1, len(meanF465), len(meanF465))/data['streams'][dopa].fs*N\n",
    "    ts2 = TRANGE[0] + np.linspace(1, len(meanF415), len(meanF415))/data['streams'][isosbestic].fs*N\n",
    "    #ts1 = ts2 since iso and dopamine are recorded simulteanosuly (I can't spell)\n",
    "\n",
    "    zerror = np.std(zall, axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
